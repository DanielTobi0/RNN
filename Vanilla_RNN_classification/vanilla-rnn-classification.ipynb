{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T10:52:57.859477Z","iopub.execute_input":"2024-05-14T10:52:57.859829Z","iopub.status.idle":"2024-05-14T10:52:58.658036Z","shell.execute_reply.started":"2024-05-14T10:52:57.859798Z","shell.execute_reply":"2024-05-14T10:52:58.657144Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/twitter_validation.csv\n/kaggle/input/twitter_training.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Vanilla RNN classification\nTwitter sentiment analysis using Vanilla RNN.\n\nThis covers for Vanilla, GRU and LSTM variant.\n\nNo much twearking to be done, when switching between variants of RNN's","metadata":{}},{"cell_type":"code","source":"# import libaries\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport time\nfrom tqdm.auto import tqdm ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:00.680397Z","iopub.execute_input":"2024-05-14T10:53:00.680894Z","iopub.status.idle":"2024-05-14T10:53:04.572298Z","shell.execute_reply.started":"2024-05-14T10:53:00.680831Z","shell.execute_reply":"2024-05-14T10:53:04.571424Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load data\ncolumn_names = ['ID', 'Game', 'Sentiment', 'Text']\n\ntrain = pd.read_csv('/kaggle/input/twitter_training.csv', names=column_names)\ntest = pd.read_csv('/kaggle/input/twitter_validation.csv', names=column_names)\n\ndel column_names\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:04.573942Z","iopub.execute_input":"2024-05-14T10:53:04.574347Z","iopub.status.idle":"2024-05-14T10:53:04.985716Z","shell.execute_reply.started":"2024-05-14T10:53:04.574321Z","shell.execute_reply":"2024-05-14T10:53:04.984808Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((74682, 4), (1000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"# train = train.iloc[:5000, :]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:04.987088Z","iopub.execute_input":"2024-05-14T10:53:04.987450Z","iopub.status.idle":"2024-05-14T10:53:04.991517Z","shell.execute_reply.started":"2024-05-14T10:53:04.987417Z","shell.execute_reply":"2024-05-14T10:53:04.990654Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Text preprocessing","metadata":{}},{"cell_type":"code","source":"# drop duplicated\ntrain.drop_duplicates(subset=['Text'], inplace=True)\ntest.drop_duplicates(subset=['Text'], inplace=True)\n\n# drop rows with na\ntrain.dropna(subset=['Text'], inplace=True)\ntest.dropna(subset=['Text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:04.993624Z","iopub.execute_input":"2024-05-14T10:53:04.994494Z","iopub.status.idle":"2024-05-14T10:53:05.047926Z","shell.execute_reply.started":"2024-05-14T10:53:04.994463Z","shell.execute_reply":"2024-05-14T10:53:05.046921Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# count vectorizer\nvectorizer = CountVectorizer()\nX_train = vectorizer.fit_transform(train['Text']).toarray()\ny_train = train['Sentiment'].map({'Negative': 0, 'Positive': 1, 'Neutral': 2, 'Irrelevant': 3}).values\n\nX_test = vectorizer.transform(test['Text']).toarray()\ny_test = test['Sentiment'].map({'Negative': 0, 'Positive': 1, 'Neutral': 2, 'Irrelevant': 3}).values\n\ndel train, test","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:05.049309Z","iopub.execute_input":"2024-05-14T10:53:05.049707Z","iopub.status.idle":"2024-05-14T10:53:09.171524Z","shell.execute_reply.started":"2024-05-14T10:53:05.049661Z","shell.execute_reply":"2024-05-14T10:53:09.170764Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Dataset to tensor","metadata":{}},{"cell_type":"code","source":"# X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n# y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n\n# X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n# y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:09.172540Z","iopub.execute_input":"2024-05-14T10:53:09.172793Z","iopub.status.idle":"2024-05-14T10:53:09.177315Z","shell.execute_reply.started":"2024-05-14T10:53:09.172770Z","shell.execute_reply":"2024-05-14T10:53:09.176500Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y=None):\n        self.x = torch.tensor(x, dtype=torch.float32).to(device)\n        self.y = torch.tensor(y, dtype=torch.long).to(device) if y is not None else None\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx] if self.y is not None else torch.empty((1, 1), dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:09.178491Z","iopub.execute_input":"2024-05-14T10:53:09.178757Z","iopub.status.idle":"2024-05-14T10:53:09.211092Z","shell.execute_reply.started":"2024-05-14T10:53:09.178733Z","shell.execute_reply":"2024-05-14T10:53:09.210186Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, y_train)\ntest_dataset = CustomDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:09.213365Z","iopub.execute_input":"2024-05-14T10:53:09.213744Z","iopub.status.idle":"2024-05-14T10:53:17.194219Z","shell.execute_reply.started":"2024-05-14T10:53:09.213711Z","shell.execute_reply":"2024-05-14T10:53:17.193382Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T10:53:17.195279Z","iopub.execute_input":"2024-05-14T10:53:17.195583Z","iopub.status.idle":"2024-05-14T10:53:17.200549Z","shell.execute_reply.started":"2024-05-14T10:53:17.195540Z","shell.execute_reply":"2024-05-14T10:53:17.199621Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Building the Network","metadata":{}},{"cell_type":"code","source":"# create RNN model\nclass VanillaRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(VanillaRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) # replace RNN with choice GRU, LSTM.\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(device) # for LSTM only\n        out, _ = self.rnn(x, h0) # replace rnn for gru, for LSTM out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :]) # batches, hidden_state(we took the last), features\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-14T11:08:39.297056Z","iopub.execute_input":"2024-05-14T11:08:39.297527Z","iopub.status.idle":"2024-05-14T11:08:39.305250Z","shell.execute_reply.started":"2024-05-14T11:08:39.297492Z","shell.execute_reply":"2024-05-14T11:08:39.304291Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# instantiate the model\ninput_size = X_train.shape[1]\nhidden_size = 256\noutput_size = 4  # number of classes to predict\nmodel = VanillaRNN(input_size, hidden_size, output_size).to(device)\n\n# define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# optimizer = optim.SGD(params=model.parameters(), lr=0.1)\n\n# accuracy function\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct/len(y_true)) * 100\n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-05-14T11:08:39.719365Z","iopub.execute_input":"2024-05-14T11:08:39.720312Z","iopub.status.idle":"2024-05-14T11:08:39.809314Z","shell.execute_reply.started":"2024-05-14T11:08:39.720280Z","shell.execute_reply":"2024-05-14T11:08:39.808526Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n              data_loader: torch.utils.data.DataLoader,\n              criterion: torch.nn.Module,\n              optimizer: torch.optim.Optimizer,\n              accuracy_fn,\n              device: torch.device = device):\n    \n    # Training loop\n    train_loss, train_acc = 0, 0\n    \n    \n    for batch, (inputs, labels) in enumerate(data_loader):\n        model.train()\n        outputs = model(inputs.unsqueeze(1))\n\n        loss = criterion(outputs.squeeze(), labels)\n        train_loss += loss\n        train_acc += accuracy_fn(labels, outputs.argmax(dim=1))\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n    print(f'Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T11:08:42.589581Z","iopub.execute_input":"2024-05-14T11:08:42.589973Z","iopub.status.idle":"2024-05-14T11:08:42.597734Z","shell.execute_reply.started":"2024-05-14T11:08:42.589942Z","shell.execute_reply":"2024-05-14T11:08:42.596712Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def test_step(data_loader: torch.utils.data.DataLoader,\n              model: torch.nn.Module,\n              criterion: torch.nn.Module,\n              accuracy_fn):\n    \n    test_loss, test_acc = 0, 0\n    \n    model.eval()\n    with torch.inference_mode():\n        for X, y in data_loader:\n            pred = model(X.unsqueeze(1))\n            # _, predicted = torch.max(pred, 1)\n            \n            test_loss += criterion(pred.squeeze(), y)\n            test_acc += accuracy_fn(y, pred.argmax(dim=1))\n            \n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T11:08:42.847154Z","iopub.execute_input":"2024-05-14T11:08:42.847592Z","iopub.status.idle":"2024-05-14T11:08:42.854135Z","shell.execute_reply.started":"2024-05-14T11:08:42.847561Z","shell.execute_reply":"2024-05-14T11:08:42.853230Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"epochs = 5\n\nfor epoch in tqdm(range(epochs)):\n    print(f'Epoch: {epoch}\\n-------------------')\n    train_step(model = model,\n                data_loader = train_dataloader,\n                criterion = criterion,\n                optimizer = optimizer ,\n                accuracy_fn = accuracy_fn,\n                device = device)\n\n    test_step(data_loader = test_dataloader,\n                model = model,\n                criterion = criterion,\n                accuracy_fn = accuracy_fn)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T11:08:43.663105Z","iopub.execute_input":"2024-05-14T11:08:43.663795Z","iopub.status.idle":"2024-05-14T11:09:01.242106Z","shell.execute_reply.started":"2024-05-14T11:08:43.663762Z","shell.execute_reply":"2024-05-14T11:09:01.241178Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292ec41ef7e245d2bd70d2c89ed22142"}},"metadata":{}},{"name":"stdout","text":"Epoch: 0\n-------------------\nTrain loss: 0.67213 | Train accuracy: 74.60%\nTest loss: 0.22371 | Test accuracy: 93.16%\n\nEpoch: 1\n-------------------\nTrain loss: 0.28199 | Train accuracy: 89.99%\nTest loss: 0.17949 | Test accuracy: 94.86%\n\nEpoch: 2\n-------------------\nTrain loss: 0.20648 | Train accuracy: 92.61%\nTest loss: 0.17353 | Test accuracy: 95.05%\n\nEpoch: 3\n-------------------\nTrain loss: 0.17391 | Train accuracy: 93.67%\nTest loss: 0.19119 | Test accuracy: 95.03%\n\nEpoch: 4\n-------------------\nTrain loss: 0.15269 | Train accuracy: 94.47%\nTest loss: 0.18712 | Test accuracy: 95.41%\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Reference: \n[Twitter Sentiment Analysis](https://www.kaggle.com/code/dheekumar/rnn-model)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}