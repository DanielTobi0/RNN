{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T07:39:47.256104Z","iopub.execute_input":"2024-05-14T07:39:47.256493Z","iopub.status.idle":"2024-05-14T07:39:47.264325Z","shell.execute_reply.started":"2024-05-14T07:39:47.256460Z","shell.execute_reply":"2024-05-14T07:39:47.263248Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/twitter_validation.csv\n/kaggle/input/twitter_training.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Vanilla RNN classification\nTwitter sentiment analysis using Vanilla RNN.","metadata":{}},{"cell_type":"code","source":"# import libaries\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport time\nfrom tqdm.auto import tqdm ","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:39:48.454389Z","iopub.execute_input":"2024-05-14T07:39:48.455359Z","iopub.status.idle":"2024-05-14T07:39:52.051571Z","shell.execute_reply.started":"2024-05-14T07:39:48.455323Z","shell.execute_reply":"2024-05-14T07:39:52.050650Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# load data\ncolumn_names = ['ID', 'Game', 'Sentiment', 'Text']\n\ntrain = pd.read_csv('/kaggle/input/twitter_training.csv', names=column_names)\ntest = pd.read_csv('/kaggle/input/twitter_validation.csv', names=column_names)\n\ndel column_names\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:44.965852Z","iopub.execute_input":"2024-05-14T07:41:44.966256Z","iopub.status.idle":"2024-05-14T07:41:45.222283Z","shell.execute_reply.started":"2024-05-14T07:41:44.966224Z","shell.execute_reply":"2024-05-14T07:41:45.221169Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"((74682, 4), (1000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"# train = train.iloc[:5000, :]","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:45.224320Z","iopub.execute_input":"2024-05-14T07:41:45.224658Z","iopub.status.idle":"2024-05-14T07:41:45.229280Z","shell.execute_reply.started":"2024-05-14T07:41:45.224630Z","shell.execute_reply":"2024-05-14T07:41:45.228227Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Text preprocessing","metadata":{}},{"cell_type":"code","source":"# drop duplicated\ntrain.drop_duplicates(subset=['Text'], inplace=True)\ntest.drop_duplicates(subset=['Text'], inplace=True)\n\n# drop rows with na\ntrain.dropna(subset=['Text'], inplace=True)\ntest.dropna(subset=['Text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:45.230389Z","iopub.execute_input":"2024-05-14T07:41:45.230705Z","iopub.status.idle":"2024-05-14T07:41:45.283467Z","shell.execute_reply.started":"2024-05-14T07:41:45.230678Z","shell.execute_reply":"2024-05-14T07:41:45.282526Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# count vectorizer\nvectorizer = CountVectorizer()\nX_train = vectorizer.fit_transform(train['Text']).toarray()\ny_train = train['Sentiment'].map({'Negative': 0, 'Positive': 1, 'Neutral': 2, 'Irrelevant': 3}).values\n\nX_test = vectorizer.transform(test['Text']).toarray()\ny_test = test['Sentiment'].map({'Negative': 0, 'Positive': 1, 'Neutral': 2, 'Irrelevant': 3}).values\n\ndel train, test","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:45.284676Z","iopub.execute_input":"2024-05-14T07:41:45.285352Z","iopub.status.idle":"2024-05-14T07:41:49.915892Z","shell.execute_reply.started":"2024-05-14T07:41:45.285323Z","shell.execute_reply":"2024-05-14T07:41:49.914941Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Dataset to tensor","metadata":{}},{"cell_type":"code","source":"# X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n# y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n\n# X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n# y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:49.919326Z","iopub.execute_input":"2024-05-14T07:41:49.920065Z","iopub.status.idle":"2024-05-14T07:41:49.924948Z","shell.execute_reply.started":"2024-05-14T07:41:49.920024Z","shell.execute_reply":"2024-05-14T07:41:49.923656Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y=None):\n        self.x = torch.tensor(x, dtype=torch.float32).to(device)\n        self.y = torch.tensor(y, dtype=torch.long).to(device) if y is not None else None\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx] if self.y is not None else torch.empty((1, 1), dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:49.926336Z","iopub.execute_input":"2024-05-14T07:41:49.926846Z","iopub.status.idle":"2024-05-14T07:41:49.941010Z","shell.execute_reply.started":"2024-05-14T07:41:49.926787Z","shell.execute_reply":"2024-05-14T07:41:49.940048Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, y_train)\ntest_dataset = CustomDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:49.942172Z","iopub.execute_input":"2024-05-14T07:41:49.942512Z","iopub.status.idle":"2024-05-14T07:41:57.456414Z","shell.execute_reply.started":"2024-05-14T07:41:49.942465Z","shell.execute_reply":"2024-05-14T07:41:57.455346Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:57.458224Z","iopub.execute_input":"2024-05-14T07:41:57.458576Z","iopub.status.idle":"2024-05-14T07:41:57.472684Z","shell.execute_reply.started":"2024-05-14T07:41:57.458546Z","shell.execute_reply":"2024-05-14T07:41:57.471547Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Building the Network","metadata":{}},{"cell_type":"code","source":"# Define RNN model\nclass VanillaRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(VanillaRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n        out, _ = self.rnn(x, h0)\n        out = self.fc(out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:57.473985Z","iopub.execute_input":"2024-05-14T07:41:57.474302Z","iopub.status.idle":"2024-05-14T07:41:57.481362Z","shell.execute_reply.started":"2024-05-14T07:41:57.474275Z","shell.execute_reply":"2024-05-14T07:41:57.480401Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# instantiate the model\ninput_size = X_train.shape[1]\nhidden_size = 256\noutput_size = 4  # Number of classes\nmodel = VanillaRNN(input_size, hidden_size, output_size).to(device)\n\n# define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# optimizer = optim.SGD(params=model.parameters(), lr=0.1)\n\n# accuracy function\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct/len(y_true)) * 100\n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:57.482995Z","iopub.execute_input":"2024-05-14T07:41:57.483694Z","iopub.status.idle":"2024-05-14T07:41:57.583467Z","shell.execute_reply.started":"2024-05-14T07:41:57.483655Z","shell.execute_reply":"2024-05-14T07:41:57.582568Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n              data_loader: torch.utils.data.DataLoader,\n              criterion: torch.nn.Module,\n              optimizer: torch.optim.Optimizer,\n              accuracy_fn,\n              device: torch.device = device):\n    \n    # Training loop\n    train_loss, train_acc = 0, 0\n    \n    \n    for batch, (inputs, labels) in enumerate(data_loader):\n        model.train()\n        outputs = model(inputs.unsqueeze(1))\n\n        loss = criterion(outputs.squeeze(), labels)\n        train_loss += loss\n        train_acc += accuracy_fn(labels, outputs.argmax(dim=1))\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n    print(f'Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:57.584728Z","iopub.execute_input":"2024-05-14T07:41:57.585079Z","iopub.status.idle":"2024-05-14T07:41:57.593929Z","shell.execute_reply.started":"2024-05-14T07:41:57.585050Z","shell.execute_reply":"2024-05-14T07:41:57.592833Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def test_step(data_loader: torch.utils.data.DataLoader,\n              model: torch.nn.Module,\n              criterion: torch.nn.Module,\n              accuracy_fn):\n    \n    test_loss, test_acc = 0, 0\n    \n    model.eval()\n    with torch.inference_mode():\n        for X, y in data_loader:\n            pred = model(X.unsqueeze(1))\n            # _, predicted = torch.max(pred, 1)\n            \n            test_loss += criterion(pred, y)\n            test_acc += accuracy_fn(y, pred.argmax(dim=1))\n            \n        test_loss /= len(data_loader)\n        test_acc /= len(data_loader)\n        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:57.595358Z","iopub.execute_input":"2024-05-14T07:41:57.595652Z","iopub.status.idle":"2024-05-14T07:41:57.606090Z","shell.execute_reply.started":"2024-05-14T07:41:57.595627Z","shell.execute_reply":"2024-05-14T07:41:57.604988Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"epochs = 5\n\nfor epoch in tqdm(range(epochs)):\n    print(f'Epoch: {epoch}\\n-------------------')\n    train_step(model = model,\n                data_loader = train_dataloader,\n                criterion = criterion,\n                optimizer = optimizer ,\n                accuracy_fn = accuracy_fn,\n                device = device)\n\n    test_step(data_loader = test_dataloader,\n                model = model,\n                criterion = criterion,\n                accuracy_fn = accuracy_fn)","metadata":{"execution":{"iopub.status.busy":"2024-05-14T07:41:57.607439Z","iopub.execute_input":"2024-05-14T07:41:57.607750Z","iopub.status.idle":"2024-05-14T07:50:48.174061Z","shell.execute_reply.started":"2024-05-14T07:41:57.607724Z","shell.execute_reply":"2024-05-14T07:50:48.173198Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24a2b1eb6f83431fa06852c5fdc6c02b"}},"metadata":{}},{"name":"stdout","text":"Epoch: 0\n-------------------\nTrain loss: 0.67180 | Train accuracy: 74.54%\nTest loss: 0.22578 | Test accuracy: 93.98%\n\nEpoch: 1\n-------------------\nTrain loss: 0.28094 | Train accuracy: 89.99%\nTest loss: 0.17227 | Test accuracy: 94.18%\n\nEpoch: 2\n-------------------\nTrain loss: 0.20594 | Train accuracy: 92.59%\nTest loss: 0.17916 | Test accuracy: 95.21%\n\nEpoch: 3\n-------------------\nTrain loss: 0.17292 | Train accuracy: 93.64%\nTest loss: 0.16512 | Test accuracy: 95.45%\n\nEpoch: 4\n-------------------\nTrain loss: 0.15197 | Train accuracy: 94.45%\nTest loss: 0.16346 | Test accuracy: 95.90%\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Reference: \n[Twitter Sentiment Analysis](https://www.kaggle.com/code/dheekumar/rnn-model)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}