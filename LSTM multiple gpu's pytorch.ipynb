{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-20T06:05:25.237917Z","iopub.execute_input":"2024-08-20T06:05:25.238239Z","iopub.status.idle":"2024-08-20T06:05:25.606935Z","shell.execute_reply.started":"2024-08-20T06:05:25.238210Z","shell.execute_reply":"2024-08-20T06:05:25.606001Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/twitter_validation.csv\n/kaggle/input/twitter_training.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Vanilla RNN classification\nTwitter sentiment analysis using Vanilla RNN.\n\nThis covers for Vanilla, GRU and LSTM variant.\n\nNo much twearking to be done, when switching between variants of RNN's","metadata":{}},{"cell_type":"code","source":"# import libaries\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport time\nfrom tqdm.auto import tqdm ","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:05:25.608890Z","iopub.execute_input":"2024-08-20T06:05:25.609274Z","iopub.status.idle":"2024-08-20T06:05:29.572300Z","shell.execute_reply.started":"2024-08-20T06:05:25.609248Z","shell.execute_reply":"2024-08-20T06:05:29.571448Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load data\ncolumn_names = ['ID', 'Game', 'Sentiment', 'Text']\n\ntrain = pd.read_csv('/kaggle/input/twitter_training.csv', names=column_names)\ntest = pd.read_csv('/kaggle/input/twitter_validation.csv', names=column_names)\n\ndel column_names\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:07:10.459967Z","iopub.execute_input":"2024-08-20T06:07:10.460326Z","iopub.status.idle":"2024-08-20T06:07:10.685725Z","shell.execute_reply.started":"2024-08-20T06:07:10.460300Z","shell.execute_reply":"2024-08-20T06:07:10.684784Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"((74682, 4), (1000, 4))"},"metadata":{}}]},{"cell_type":"code","source":"# train = train.iloc[:5000, :]","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:07:12.752537Z","iopub.execute_input":"2024-08-20T06:07:12.752872Z","iopub.status.idle":"2024-08-20T06:07:12.757041Z","shell.execute_reply.started":"2024-08-20T06:07:12.752847Z","shell.execute_reply":"2024-08-20T06:07:12.755966Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Text preprocessing","metadata":{}},{"cell_type":"code","source":"# drop duplicated\ntrain.drop_duplicates(subset=['Text'], inplace=True)\ntest.drop_duplicates(subset=['Text'], inplace=True)\n\n# drop rows with na\ntrain.dropna(subset=['Text'], inplace=True)\ntest.dropna(subset=['Text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:07:13.451699Z","iopub.execute_input":"2024-08-20T06:07:13.452577Z","iopub.status.idle":"2024-08-20T06:07:13.496383Z","shell.execute_reply.started":"2024-08-20T06:07:13.452535Z","shell.execute_reply":"2024-08-20T06:07:13.495564Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# count vectorizer\nvectorizer = CountVectorizer()\nX_train = vectorizer.fit_transform(train['Text']).toarray()\ny_train = train['Sentiment'].map({'Negative': 0, 'Positive': 1, 'Neutral': 2, 'Irrelevant': 3}).values\n\nX_test = vectorizer.transform(test['Text']).toarray()\ny_test = test['Sentiment'].map({'Negative': 0, 'Positive': 1, 'Neutral': 2, 'Irrelevant': 3}).values\n\ndel train, test","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:07:16.297730Z","iopub.execute_input":"2024-08-20T06:07:16.298093Z","iopub.status.idle":"2024-08-20T06:07:20.283881Z","shell.execute_reply.started":"2024-08-20T06:07:16.298051Z","shell.execute_reply":"2024-08-20T06:07:20.282833Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Dataset to tensor","metadata":{}},{"cell_type":"code","source":"# X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n# y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n\n# X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n# y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:05:34.096340Z","iopub.execute_input":"2024-08-20T06:05:34.096733Z","iopub.status.idle":"2024-08-20T06:05:34.101144Z","shell.execute_reply.started":"2024-08-20T06:05:34.096700Z","shell.execute_reply":"2024-08-20T06:05:34.100207Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y=None):\n        self.x = torch.tensor(x, dtype=torch.float32).to(device)\n        self.y = torch.tensor(y, dtype=torch.long).to(device) if y is not None else None\n\n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        return self.x[idx], self.y[idx] if self.y is not None else torch.empty((1, 1), dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:05:34.102415Z","iopub.execute_input":"2024-08-20T06:05:34.102791Z","iopub.status.idle":"2024-08-20T06:05:34.163244Z","shell.execute_reply.started":"2024-08-20T06:05:34.102762Z","shell.execute_reply":"2024-08-20T06:05:34.162286Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_train, y_train)\ntest_dataset = CustomDataset(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:05:34.164546Z","iopub.execute_input":"2024-08-20T06:05:34.164978Z","iopub.status.idle":"2024-08-20T06:05:42.168414Z","shell.execute_reply.started":"2024-08-20T06:05:34.164947Z","shell.execute_reply":"2024-08-20T06:05:42.167436Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\ndel train_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:05:42.171676Z","iopub.execute_input":"2024-08-20T06:05:42.171960Z","iopub.status.idle":"2024-08-20T06:05:42.464062Z","shell.execute_reply.started":"2024-08-20T06:05:42.171936Z","shell.execute_reply":"2024-08-20T06:05:42.462997Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Building the Network","metadata":{}},{"cell_type":"code","source":"# create RNN model\nclass VanillaRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(VanillaRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True) # replace RNN with choice GRU, LSTM.\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(device) # for LSTM only\n        out, _ = self.rnn(x, h0) # replace rnn for gru, for LSTM out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :]) # batches, hidden_state(we took the last), features\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:11:36.386718Z","iopub.execute_input":"2024-08-20T06:11:36.387038Z","iopub.status.idle":"2024-08-20T06:11:36.394290Z","shell.execute_reply.started":"2024-08-20T06:11:36.387014Z","shell.execute_reply":"2024-08-20T06:11:36.393438Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# instantiate the model\ninput_size = X_train.shape[1]\nhidden_size = 512\noutput_size = 4  # number of classes to predict\nmodel = VanillaRNN(input_size, hidden_size, output_size).to(device)\nmodel = torch.nn.DataParallel(model, device_ids=[0, 1]).to(device)\n\n# define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n# optimizer = optim.SGD(params=model.parameters(), lr=0.1)\n\n# accuracy function\ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct/len(y_true)) * 100\n    return acc\n\ndel y_train, X_test, y_test","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:11:36.403991Z","iopub.execute_input":"2024-08-20T06:11:36.404232Z","iopub.status.idle":"2024-08-20T06:11:36.584880Z","shell.execute_reply.started":"2024-08-20T06:11:36.404212Z","shell.execute_reply":"2024-08-20T06:11:36.584087Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n              data_loader: torch.utils.data.DataLoader,\n              criterion: torch.nn.Module,\n              optimizer: torch.optim.Optimizer,\n              accuracy_fn,\n              device: torch.device = device):\n    \n    # Training loop\n    train_loss, train_acc = 0, 0\n    \n    \n    for batch, (inputs, labels) in enumerate(data_loader):\n        model.train()\n        outputs = model(inputs.unsqueeze(1))\n\n        loss = criterion(outputs.squeeze(), labels)\n        train_loss += loss\n        train_acc += accuracy_fn(labels, outputs.argmax(dim=1))\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    train_loss /= len(data_loader)\n    train_acc /= len(data_loader)\n    print(f'Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:11:36.586312Z","iopub.execute_input":"2024-08-20T06:11:36.586601Z","iopub.status.idle":"2024-08-20T06:11:36.593823Z","shell.execute_reply.started":"2024-08-20T06:11:36.586577Z","shell.execute_reply":"2024-08-20T06:11:36.592872Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def test_step(data_loader: torch.utils.data.DataLoader,\n              model: torch.nn.Module,\n              criterion: torch.nn.Module,\n              accuracy_fn):\n    \n    test_loss, test_acc = 0, 0\n    \n    model.eval()\n    #with torch.inference_mode(): Uncomment to train on single gpu\n    for X, y in data_loader:\n        pred = model(X.unsqueeze(1))\n        # _, predicted = torch.max(pred, 1)\n\n        test_loss += criterion(pred.squeeze(), y)\n        test_acc += accuracy_fn(y, pred.argmax(dim=1))\n\n    test_loss /= len(data_loader)\n    test_acc /= len(data_loader)\n    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:11:36.594902Z","iopub.execute_input":"2024-08-20T06:11:36.595195Z","iopub.status.idle":"2024-08-20T06:11:36.605965Z","shell.execute_reply.started":"2024-08-20T06:11:36.595172Z","shell.execute_reply":"2024-08-20T06:11:36.605262Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"epochs = 5\n\nfor epoch in tqdm(range(epochs)):\n    print(f'Epoch: {epoch}\\n-------------------')\n    train_step(model = model,\n                data_loader = train_dataloader,\n                criterion = criterion,\n                optimizer = optimizer ,\n                accuracy_fn = accuracy_fn,\n                device = device)\n\n    test_step(data_loader = test_dataloader,\n                model = model,\n                criterion = criterion,\n                accuracy_fn = accuracy_fn)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T06:11:36.607972Z","iopub.execute_input":"2024-08-20T06:11:36.608461Z","iopub.status.idle":"2024-08-20T06:13:34.447503Z","shell.execute_reply.started":"2024-08-20T06:11:36.608417Z","shell.execute_reply":"2024-08-20T06:13:34.446454Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4a711f8bcb2448d876a45b3bde5a1b4"}},"metadata":{}},{"name":"stdout","text":"Epoch: 0\n-------------------\nTrain loss: 0.65597 | Train accuracy: 75.34%\nTest loss: 0.22540 | Test accuracy: 93.79%\n\nEpoch: 1\n-------------------\nTrain loss: 0.28668 | Train accuracy: 89.65%\nTest loss: 0.17725 | Test accuracy: 94.89%\n\nEpoch: 2\n-------------------\nTrain loss: 0.21169 | Train accuracy: 92.38%\nTest loss: 0.15432 | Test accuracy: 95.80%\n\nEpoch: 3\n-------------------\nTrain loss: 0.18151 | Train accuracy: 93.46%\nTest loss: 0.16692 | Test accuracy: 95.70%\n\nEpoch: 4\n-------------------\nTrain loss: 0.16205 | Train accuracy: 94.08%\nTest loss: 0.17227 | Test accuracy: 95.45%\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Reference: \n[Twitter Sentiment Analysis](https://www.kaggle.com/code/dheekumar/rnn-model)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}